%------------------------------------------------------------------------------%
%                            serialization library                             %
%------------------------------------------------------------------------------%

\clearpage{}
\section{Serialization library}

In this section, we will present the optimizations added to a serialization
library originally developed as a school project at ISIMA
\cite{projectzz3isima}. The purpose of these optimizations is to make this
library usable in \gls{hpc} application. In our context, the objective was to
use this library to transfer data between nodes using MPI in the cluster
version of \gls{hh}. We will also describe some of the new features of the
library.

\subsection{The principle}

First, we will explain the principles behind the first version of the
library. We will not go too deeply into details, as these have already been
described in \cite{projectzz3isima}.\\

The basic purpose of the library is to enable serialization of C++ by writing as
little code as possible, similar to the use of decorators in languages such as
Java. The library provides macros that are used in the serialized classes. These
macros generate the \texttt{serialize} and \texttt{deserialize} functions in the
class. Listing \ref{lst:serexamplebase} illustrate how to make a class
serializable, using the interface from the first version of the library. The
\texttt{SERIALIZABLE} macro generates the serialization functions, and the
\texttt{SERIALIZER} macro initializes the \textit{serializer}.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
  #include <serializer/serializable.hpp>

  class MyClass {
      SERIALIZABLE(int, double);
    public:
      MyClass(int x, double y): SERIALIZER(x_, y_), x_(x), y_(y) {}

    private:
      int x_ = 0;
      double y_ = 0;
  };
\end{minted}
\caption{Example of a class serialization}
\label{lst:serexamplebase}
\end{listing}
%- end listing --------------------------------------------------------------}}}

The \textit{serializer} is an attribute added to the class by the
\texttt{SERIALIZABLE} macro. It contains a data structure, the
\texttt{AttrContainer}, which stores references to the attributes of the
serialized class, in order to be able to access their values or modify them.
This data structure functions similarly to a list, in which each node can store
a different data type. It can also be compared to a \texttt{tuple}. In the
generated serialization function, we call the methods of the \textit{serializer}
to initiate the serialization of the attributes in the container. This mechanism
has changed in the latest version of the library, which will be explained in the
section \ref{sec:sernewinterface}.

To serialize the attributes, we use a specialized class called
\texttt{Convertor}. This class is consists of very generic template functions
capable of converting most of the types of the standard library, as well as some
external types if they meet certain conditions. This functionality means that
the library users do not need to translate the serialized members by hand,
everything is done automatically in the \textit{convertor}. Additionally, it is
possible to create a custom \textit{convertor} class, either to add support for
external types or to serialize polymorphic objects. The class has been changed
since the first version of the library, and these modifications will be
explained in the section \ref{sec:convertor}.\\

Now that we have explained the fundamental principle of the first version of the
library, we will now detail the optimizations and the features that have been
added to it, as well as the new interface.

\subsection{The new interface}
\label{sec:sernewinterface}

The interface of the first version of the library had several significant
limitations, and was not as simple as it should have been. The new interface is
even simpler and solves the issues present in the first one.\\

The previous interface required the use of two macros that were generating a
significant amount of code. The macro \texttt{SERIALIZABLE} added a
\textit{serializer} attribute to the class. As a result, the users had to
implement their own constructors rather that using those automatically generated
by the compiler. Consequently, a lot of unnecessary additional code had to be
written to manage the \textit{serializer} attribute.

Another issue of the old interface was the extensive use of intermediate layers.
To serialize a class, we had to call the functions generated by the macros
within the class. These functions where using methods from the
\textit{serializer} that were using the attribute container that was calling the
\textit{convertor} methods. The usage of all these functions had a big cost on
the performances. Furthermore, it appeared that the \texttt{AttrContainer} was
inefficient because of the recursive calls.

The new interface does not use the \texttt{AttrContainer} and the
\textit{serializer}. Furthermore, only one macro, \texttt{SERIALIZE}, is used to
generate the serialization functions. Listing \ref{lst:newinterfex} illustrates
the usage of the new macro.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
  class MyClass {
    public:
      MyClass(int x, double y) x_(x), y_(y) {}

      // the class is now serializable
      SERIALIZE(x_, y_);

    private:
      int x_ = 0;
      double y_ = 0;
  };
\end{minted}
\caption{Serializing a class with the new interface}
\label{lst:newinterfex}
\end{listing}
%- end listing --------------------------------------------------------------}}}

The generated serialization functions now use external functions that directly
invoke the \textit{convertor}. Listing \ref{lst:externserialize} shows the
implementation of the \texttt{serialize} function. The external function is used
rather that generating all the code inline as it simplifies maintenance.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
template <typename Conv, typename... Args>
constexpr void
serialize(std::string& str, mtf::serialize_arg_type<Args>... args) {
  ([&str, &args]{ Conv().serialize_(args, str); }(), ...);
}
\end{minted}
\caption{External \texttt{serialize} function}
\label{lst:externserialize}
\end{listing}
%- end listing --------------------------------------------------------------}}}

\subsection{Binary serialization}

The first version of the library was generating a human-readable string with a
format similar to JSON. The new version uses the binary format instead. The
binary format is more efficient since it takes less space and is very easy to
parse. Moreover, it allows the removal of a lot of unnecessary information. For
instance, the previous format required to know the identifiers of the member
variables of the class. The new format assumes that the data will always be
serialized and deserialized in the same order, eliminating the need for the
identifiers. Furthermore, the previous format required to have separators in
the string to identify the beginning and the end of objects, arrays, strings
(that had to be escaped manually\footnote{The string were represented between
\texttt{'\"'}, so we had to escape potential the double quote character inside
the string in order for them not to be considered as a separator during the
deserialization.}), \dots

To serialize fundamental types in binary, we use \texttt{std::bit\_cast} to
convert the address of the serialized variable to \texttt{char*} and vice-versa.
For the containers and strings, the process begins by writing the number of
elements (on a \texttt{size\_t}), followed the elements themselves. When a
serializing a pointer, we first add a character (either \texttt{v} or
\texttt{n}) to specify if the pointer is valid or null. If the pointer is null,
there is nothing else to add. Otherwise, we deserialize the element on which the
pointer points to. During the deserialization, the pointers are dynamically
allocated if the variable is null, otherwise, the pointed value is modified
directly. This is important, especially for dynamic arrays since the dynamic
allocation is a slow process. Pointers can lead to segmentation error or memory
leaks if they are not handled properly. In our situation, there are no solutions
to prevent such behaviors, so we assume that the user of the library do things
well or do not use pointers.

\subsubsection{Example}

To visually explain how the data are organized in the serialized string, let us
consider an example. We will use 2 classes, \texttt{MyClass} shown in listing
\ref{lst:serexmyclass} and \texttt{Class2} defined in listing
\ref{lst:serexmysecondclass}.

The class \texttt{MyClass} has five attributes. The first two attributes have
fundamental types \texttt{int} and \texttt{double}. The third attribute is a
vector of integers, followed by a pointer to a double. The last attribute is a
shared pointer on a \texttt{Class2} object.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
  struct MyClass {
    int i;
    double d;
    std::vector<int> v = {};
    double *ptr = nullptr;
    std::shared_ptr<Class2> s_ptr = nullptr;
  };
\end{minted}
\caption{Definition of MyClass}
\label{lst:serexmyclass}
\end{listing}
%- end listing --------------------------------------------------------------}}}

The class \texttt{Class2} has only one attribute which is a string.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
  struct Class2 {
    std::string id;
  };
\end{minted}
\caption{Definition of Class2}
\label{lst:serexmysecondclass}
\end{listing}
%- end listing --------------------------------------------------------------}}}

An object \texttt{MyClass} is instantiated with the values that are described in
the table \ref{tbl:serexvals}.

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|}
 \hline
 Attributes & Values \\
 \hline\hline
  i & 14 \\
 \hline
  d & 1.3 \\
 \hline
  v & \{ 1, 2, 3 \} \\
 \hline
  ptr & nullptr \\
 \hline
  s\_ptr & @address \\
 \hline\hline
  s\_ptr.id & "name" \\
 \hline
\end{tabular}
\caption{Values of the attributes in the object \texttt{myClass}}
\label{tbl:serexvals}
\end{table}

If we try to serialize this object, we will obtain the following output:

\begin{format}
  7 MyClass 14 1.3 3 1 2 3 n v 13 Class2 4 name
  [7: MyClass] [14] [1.3] [3: 1, 2, 3] [n] [v: [13: Class2] [4: name]]
\end{format}\leavevmode\newline

The first line is the content of the final string (the values on hexadecimal
have been translated). On the second line the different part of the string have
been regrouped between square brackets. The string always begins with the
identifier of the type of the serialized class. For instance, an object of type
\texttt{MyClass} begins with \textit{MyClass}. The name of the type is the only
meta-data stored in the serialized string. It should be used to construct the
right object when we only have the serialized string (when we deserialize a
polymorphic type for instance). Additionally, the content of the containers is
always preceded by the number of elements. For instance, \texttt{v} contains
three elements, so its content is preceded by \texttt{3}. Finally, the null
pointers are identified with the letter \texttt{n} and the valid ones with the
letter \texttt{v} followed by the content as shown for the attribute
\texttt{s\_ptr}.

\subsubsection{C-Struct optimization}

It is possible, even in C++, to use \texttt{std::bit\_cast} on \gls{cstruct},
which can be very fast. However, determining when this can be done is difficult.
Indeed, we cannot directly cast a structure that contains pointers or complex
data structures, such as vectors. With the new interface, we could make the test
by iterating on the list of the types of the serialized members. However, in
this case, there is no guaranty that the user wants to serialize all the data in
the class. There may be members with complex types that are not serialized, and
attempting to cast the structure would not be optimized. The easiest way to know
if it is possible to use the technique is by letting the user decide on its own.
A dedicated macro has been added in the new interface.

\subsection{Redesigning the convertor}
\label{sec:convertor}

Since most types are serialized automatically, it was required for the user to
have a way to manually add conversion functions for external types. Indeed, the
users do not always have the possibility to make classes serializable. For
instance, with the Qt framework, we do not have access to the class
\texttt{QString} and this class cannot be serialized by the functions of the
default convertor.

In the previous version of the library, all the convertor functions were defined
in the macro \texttt{CONVERTOR}. This macro had to be used at the end of each
convertor class. This was done because the custom conversion functions needed to
be defined before the default ones in order for the code to compile. To
understand why basic inheritance could not be used, we will consider the
following example: the user wants to serialize a class that holds a vector of an
\texttt{Unknown} type. This type is an external one, and it is not supported by
default, so it requires implementing a custom convertor using inheritance. Now,
we are going to try to compile the code. During compilation, when serializing a
vector, the dedicated conversion function is in the base class of the custom
convertor. However, when converting the vector, we need to invoke a function
that handles the elements within the vector. This function defined in the
subclass is inaccessible from the base class. One solution would be to use
virtual functions. However, it was not possible by that time because all the
conversion function were templates as \gls{sfinae} was used to differentiate
one function from another.

Using such a macro in the library was a significant problem. Indeed, the first
issue is the difficulty of maintaining the code. Because all the functions were
defined in the macro, the compiler errors were difficult to read, and it was not
possible to use the full power of an IDE (there are no error in macros). The
second issue is the fact that a lot of code was generated. In fact, if the user
wanted to create multiple convertor classes, there was a lot of code
duplication. Finally, the usage of such a macro from the user's point of view
was very unintuitive.

To remove the \texttt{CONVERTOR} macro, a method similar to the behaviors of
\gls{hh} was utilized \cite{bardakoff2021analysis}. The \texttt{Convert}
behavior is a template class with two virtual pure functions, \texttt{serialize}
and \texttt{deserialize}. These functions should be overridden in the user's
convertor class. The fact that the class is template but not the methods allows
them to be virtual. The definition of this class is shown on the listing
\ref{lst:convert}.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
template <typename T> struct Convert {
    virtual void serialize(T const &, std::string &) const = 0;
    virtual void deserialize(std::string_view &, T &) = 0;
};
\end{minted}
\caption{Convert class}
\label{lst:convert}
\end{listing}
%- end listing --------------------------------------------------------------}}}

The default convertor class has non-static member functions
\texttt{serialize\_} and \texttt{deserialize\_} (an \texttt{\_} is used to avoid
conflicts with the functions from \texttt{Convert}). These methods are
templates, and they use concepts from C++20 instead of \gls{sfinea}. The usage of
concepts is very important in this case because they are more flexible than
\gls{sfinae}. In fact, they easily allow the definition of fallback functions
that are called when a non-supported type is serialized. These fallback
methods use the functions from \texttt{Convert} as we can see in the listing
\ref{lst:fallbackserialize}. In these functions, exceptions are used to create
useful error message at runtime. The choice of generating errors at runtime and
not at compile time (using \texttt{static\_assert}) was made because the error
messages are clearer, and more readable as they are not lost in the compiler
output.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
  template <serializer::tools::concepts::NonSerializable T>
  void serialize_(T const &elt, std::string str) const {
      if constexpr (tools::mtf::contains_v<T, AdditionalTypes...>) {
          // we need a static cast because of implicit constructors (ex:
          // pointer to shared_ptr)
          static_cast<const Convert<T> *>(this)->serialize(elt, str);
      } else {
          throw serializer::exceptions::UnsupportedTypeError<T>();
      }
  }
\end{minted}
\caption{Fallback serialization method}
\label{lstd:fallbackserialize}
\end{listing}
%- end listing --------------------------------------------------------------}}}

The last important thing is the fact that the default convertor inherits from
multiple \texttt{Convert} classes (one per new type added). To achieve that, we
can see on the listing \ref{lst:convertor} that we use the fold expressions with
a variadic template.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
template <typename... AdditionalTypes>
struct Convertor : Convert<AdditionalTypes>... { /* ... */ };
\end{minted}
\caption{Convertor class}
\label{lst:convertor}
\end{listing}
%- end listing --------------------------------------------------------------}}}

The new \texttt{Convertor} class is then easier to use than the old macro. It
is also easier to maintain since macros in C and C++ are not made to contain
such an amount of code. Lastly, with this version, there is less code
duplication which makes this library usable in a case where memory is limited
(embedded C++ applications for instance).

\subsection{New features}

In addition to the optimization, some new features have been implemented. They
will be presented here.

\subsubsection{Static arrays}

A conversion function has been implemented for static arrays. In order to
serialize arrays, we need to know their sizes. For this, we use
\texttt{std::extent\_v}. For example, \texttt{std::extent\_v<T[N]>} returns
\texttt{N}. The conversion function is recursive and uses
\texttt{std::remove\_extent\_t} to convert multidimensional arrays. The listing
\ref{lst:serstaticarr}, illustrate static arrays serialization.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
class MyClass {
  public:
    /* ... */
    SERIALIZE(arr_, grid_);

  private:
    int arr_[10];
    int grid_[10][10];
};
\end{minted}
\caption{Example: serializing static arrays}
\label{lst:serstaticarr}
\end{listing}
%- end listing --------------------------------------------------------------}}}

\subsubsection{Dynamic arrays}

To be serialized, dynamic arrays need to be differentiated from the standard
pointers. Furthermore, the serialization also requires their size, which might
not be known at compile time. To solve these problems, a wrapper type
\texttt{DynamicArray} was implemented. The definition of this class is shown on
the listing \ref{lst:dynamicarray}.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
template <concepts::Pointer T, typename DT, typename... DTs>
struct DynamicArray {
    explicit DynamicArray(T &mem, DT dim, DTs... dims)
        : mem(mem), dimensions(dim, dims...) {}

    explicit DynamicArray(T &mem, std::tuple<DT, DTs...> dimensions)
        : mem(mem), dimensions(dimensions) {}

    T &mem;
    std::tuple<DT, DTs...> dimensions;
};
\end{minted}
\caption{\texttt{DynamicArray} class}
\label{lst:dynamicarray}
\end{listing}
%- end listing --------------------------------------------------------------}}}

The \texttt{DynamicArray} class stores a reference to the member variable
holding the array's pointer. This reference is used to facilitate the change of
the pointer (potential allocation or free on deserialization). The dimensions of
the array are stored in a tuple. The types of the dimensions are configurable,
allowing users to pass references to member variables holding the dimensions, as
well as values if the size is known at compile time. The number of dimensions is
not related to the dimensions of the pointer. Users can have multidimensional
arrays stored in a 1D pointers, and specify all the dimensions to the
\texttt{DynamicArray}. For instance, we can have the following type:
\texttt{DynamicArray<double*, size\_t\&, size\_t>}. In this example,   2D array
(matrix) stored in a 1D pointer. The first dimension of this matrix might be
variable, so it is store in a member variable given by reference to the
\texttt{DynamicArray}. The second dimension is constant, so it is passed by
value.

Listing \ref{lst:serdynamicarr} shows an example of serializing a class with
dynamic array attributes. In this example, the macro \texttt{SER\_DARR\_T} is
used to generate the type of the dynamic array. For instance,
\texttt{SER\_DARR\_T(types...)} is expanded to
\texttt{serializer::tools::DynamicArray<types...>} (the macro to avoids writing
the namespaces). The class \texttt{MyClass} holds two dynamic arrays:
\texttt{arr1D\_} and \texttt{arr2D\_}. The size of \texttt{arr1D\_} and
\texttt{*arr2D\_} is known at compile time (5 and 2), whereas the size of
\texttt{arr2D\_} is known at runtime (only when \texttt{allocArr2D} is called).
The size of \texttt{arr2D\_} is then stored in a variable that is serialized and
that is taken by reference by the \texttt{DynamicArray} constructor as explained
earlier.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
class MyClass {
  public:
    explicit MyClass() : arr1D_(new int[5]) { }
    ~MyClass() { /* free memory */ }
    void allocArr2D(size_t arr2DHeight) { /* ... */ }
    /* ... */
    SERIALIZE(arr2DHeight_,
              SER_DARR_T(int *, size_t)(arr1D_, 5),
              SER_DARR_T(int **, size_t &, size_t)(arr2D_, arr2DHeight_, 2));

  private:
    int *arr1D_ = nullptr;
    int **arr2D_ = nullptr;
    size_t arr2DHeight_ = 0;
};
\end{minted}
\caption{Example: serializing dynamic arrays}
\label{lst:serdynamicarr}
\end{listing}
%- end listing --------------------------------------------------------------}}}

\subsubsection{Functions}

Finally, it is now possible to execute functions at any stage of the
serialization or deserialization. Functions can be used to handle specific
cases. For example, they can be used to serialize complex objects with cyclic
references. Indeed, the library is not able to detect if a pointer or a
reference has already been serialized. It would be possible to perform this
verification, however, this would impact the performances. Now, to do that, it
is possible to use a function that will either create a link during the
deserialization (link the child to it's father in a tree) or perform more
complex operations (coloring nodes when serializing a cyclic graph). The
functions can be defined globally or inside the class using a lambda expression
or a static function.

From the library's developer point of view, these functions can be used for
debugging. In fact, as we have already explained, the attributes are serialized
in the order they appear in the macro parameters, and this is also the case for
functions. For instance, functions can be used to print the values of each
member, as well as the value of the serialized string, before and after the
members are serialized.

It is not possible to use any function, for now, only the type
\texttt{function\_t} is accepted. Its definition is shown on the listing
\ref{lst:functiont}.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
using function_t = std::function<void(Phases, std::string_view const &)>;
\end{minted}
\caption{Serializer function type}
\label{lst:functiont}
\end{listing}
%- end listing --------------------------------------------------------------}}}

The functions take two parameters:

\begin{itemize}
  \item The phase that is either \texttt{Phases::Serialization} or
    \texttt{Phases::deserialization}. It is used to know if we are serializing
    or deserializing.
  \item A constant string view that is either the result of the serialization or
    the deserialized string depending on which phase is executed. It has been
    made constant by choice as the user should not be allowed to change the
    string (we do not want him to break something). This parameter is more
    usefull for debugging.
\end{itemize}

It is important to mention that the type \texttt{function\_t}, as well as the
type \texttt{DynamicArray}, are not taken by reference in the \texttt{serialize}
function. This is due to the fact that we want to be able to create the objects
directly in the \texttt{SERIALIZE} macro. To achieve this, a dedicated
meta-function as been written, shown in the listing \ref{lst:mlargtype}.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
template <typename T> struct arg_type { using type = T &; };

template <> struct arg_type<function_t> { using type = function_t; };

template <typename T, typename DT, typename... DTs>
struct arg_type<serializer::tools::DynamicArray<T, DT, DTs...>> {
    using type = serializer::tools::DynamicArray<T, DT, DTs...>;
};
\end{minted}
\caption{Usage of \texttt{arg\_type\_t}}
\label{lst:mlargtype}
\end{listing}
%- end listing --------------------------------------------------------------}}}

The listing \ref{lst:treenode} illustrate how to serialize a node inside a
binary research tree. In this example, a node has four attributes: the value
stored in the node, the left and the right children, and the father node. In
this case, we want to save the link between the child node and the father node,
however, it is not possible to serialize the father node directly since it is a
cyclic reference. Instead, we use a function to recreate the pointer link at the
end of the deserialization. We can notice that once more, a macro is used to
simplify the syntax. There are three helper macros for functions:

\begin{itemize}
  \item \texttt{SER\_SFUN}: generates a lambda that is executed during the
    serialization.
  \item \texttt{SER\_DFUN}: generates a lambda that is executed during the
    deserialization.
  \item \texttt{SER\_FUN}: generates a lambda that is executed during both
    phases.
\end{itemize}

Since macros substitute text, we still have access to the parameters of the
functions, even if they are not visible. The phase parameter is named
\texttt{phase} and the string view parameter is named \texttt{str}.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
template <typename T>
struct Node {
  public:
    explicit Node(T value = 0): value(value) {}
    ~Node() { /* ... */ }

    /* ... */

    SERIALIZE(this->value, left, right, SER_DFUN({
         if (this->left)
             this->left->father = this;
         if (this->right)
             this->right->father = this;
     }))

    T value;
    Node<T> *father = nullptr;
    Node<T> *left = nullptr;
    Node<T> *right = nullptr;
};
\end{minted}
\caption{Example: using a function for serializing a tree node}
\label{lst:treenode}
\end{listing}
%- end listing --------------------------------------------------------------}}}

\clearpage{}
\subsection{The performances}

The performances of the library have been drastically improved compared to the
first version. However, the serialization remains slightly slower compared to
other libraries such as \textit{cereal} or \textit{cista}. Comparisons between
the libraries have been made using a benchmark repository available on GitHub:
\texttt{felixguendling/cpp-serialization-benchmark}. The benchmark creates and
serialize a graph with more that 18k nodes. Listing \ref{lst:graph} shows the
structure that was used in the benchmark.

%- begin listing ------------------------------------------------------------{{{
\begin{listing}[ht!]
\begin{minted}[frame=lines,framesep=2mm,baselinestretch=1.2,fontsize=\normalsize,linenos]{C++}
struct serializer_graph {
  SERIALIZE(nodes_);

  struct edge {
    SERIALIZE(from_, to_, weight_);
    uint16_t from_, to_;
    uint16_t weight_;
  };

  struct node {
    SERIALIZE(id_, name_, out_, in_);
    uint16_t id_;
    std::string name_;
    std::vector<edge> out_ = {};
    std::vector<edge> in_ = {};
  };
  /* ... */
  std::vector<node> nodes_ = {};
};
\end{minted}
\caption{Graph structure of the benchmark}
\label{lst:graph}
\end{listing}
%- end listing --------------------------------------------------------------}}}

As shown by the results, the serialization is slower that most of the other
libraries. However, in terms of memory usage, the library performs well.

\begin{terminal}
--------------------------------------------------------------------------
Benchmark                Time             CPU   Iterations UserCounters...
--------------------------------------------------------------------------
capnp                  997 ms          997 ms            1 size=50.5093M
cista_offset_slim     83.1 ms         83.1 ms            7 size=25.317M
cereal                1109 ms         1108 ms            1 size=37.829M
serializer            1728 ms         1728 ms            1 size=37.829M
fbs                  11369 ms        11367 ms            1 size=62.998M
cista_raw             7789 ms         7788 ms            1 size=176.378M
cista_offset          8278 ms         8277 ms            1 size=176.378M
zpp_bits              16.3 ms         16.3 ms           39 size=37.8066M
\end{terminal}\leavevmode\newline

These are the results for the deserialization. We can see that the
deserialization is relatively efficient compared to the serialization.

\begin{terminal}
----------------------------------------------------------
Benchmark                Time             CPU   Iterations
----------------------------------------------------------
capnp                0.003 ms        0.003 ms       227360
cista_offset_slim     37.8 ms         37.8 ms           19
fbs                   1386 ms         1385 ms            1
cista_offset          2512 ms         2512 ms            1
cista_raw             2346 ms         2346 ms            1
cereal                1007 ms         1007 ms            1
serializer            1004 ms         1004 ms            1
zpp_bits              11.3 ms         11.3 ms           56
cista_raw             1196 ms         1196 ms            1
\end{terminal}\leavevmode\newline

Some more optimizations will be done in the future to improve the serialization.
Moreover, binary serialization itself might not be enough to obtain good
performances, and should be used alongside other techniques. For instance, some
libraries rely on alignment to optimize the size of the result binary stream.

\subsection{Conclusion}

In this section, we have described the concept behind the serialization library,
and we have explained how it has been optimized. The usage of binary
serialization and simpler data structures that do not involve many pointers such
as the strings allowed us to improve the performances compared to the previous
version of the library. Furthermore, the code has been improved by removing the
\textit{CONVERTOR} macro. Some new features have also been added to enhance the
capabilities of this tool. Static and dynamic arrays are now serializable, and
we can also execute code during the serialization or the deserialization.
Finally, even more optimizations should be added in the future to compete with
the other libraries available on the market.
